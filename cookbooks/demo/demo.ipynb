{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1ec745-507f-4c67-802a-f0b33fc8b1a9",
   "metadata": {},
   "source": [
    "# Mythic AI Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34176e1-b9b1-4c40-9e90-776a455c4fb7",
   "metadata": {},
   "source": [
    "### Download TTS engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b54f41-993d-4c47-9fc8-4e46f497634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloaded: en_US-amy-low\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p runtimes && cd runtimes && python3 -m piper.download_voices en_US-amy-low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2c41a-3869-4ad7-9864-f183f707d4b2",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f12106d-5a69-4067-a45c-4c95370117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from piper import PiperVoice\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1167f-2e64-4271-aa35-0a22f854db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will auto-download the file from HF (cached), then load it.\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"bartowski/mistralai_Voxtral-Mini-3B-2507-GGUF\",\n",
    "    filename=\"mistralai_Voxtral-Mini-3B-2507-Q4_K_S.gguf\",\n",
    "    # Optional performance knobs:\n",
    "    n_ctx=8192,\n",
    "    n_gpu_layers=-1,       # set >0 or -1 for full offload if you have CUDA/Metal build\n",
    "    chat_format=\"hf\",      # use HF chat template if present; remove if you prefer raw completions\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Use like normal:\n",
    "out = llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Give me two sentences about Voxtral Mini.\"}],\n",
    "    max_tokens=200,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    ")\n",
    "print(out[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cfc2f-a74d-48aa-a806-7318bb8ead71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
